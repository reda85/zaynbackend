// backend/services/pdfProcessor.js (ES6 version)
import fs from 'fs-extra';
import path from 'path';
import { execSync } from 'child_process';
import pLimit from 'p-limit';
import { createClient } from '@supabase/supabase-js';

// Supabase client
const supabase = createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY
);

/**
 * Traiter un PDF en tiles avec parall√©lisation
 */
async function processPdfToTiles({ 
  pdfBuffer, 
  projectId, 
  planId,
  fileName, 
  requestId,
  onProgress 
}) {
  let tmpDir;
  
  try {
    // Cr√©er le dossier temporaire
    const osTmpDir = process.env.TMPDIR || '/tmp';
    tmpDir = path.join(osTmpDir, `zyn-${requestId}`);
    await fs.ensureDir(tmpDir);
    
    const inputPdf = path.join(tmpDir, 'input.pdf');
    const linearizedPdf = path.join(tmpDir, 'linearized.pdf');
    const pagesDir = path.join(tmpDir, 'pages');
    await fs.ensureDir(pagesDir);
    
    await fs.writeFile(inputPdf, pdfBuffer);
    
    // Upload du PDF original vers Supabase
    const safeBase = fileName.replace(/\.pdf$/i, '').replace(/[^a-z0-9]/gi, '_');
    const pdfStoragePath = `${projectId}/${safeBase}.pdf`;
    
    console.log(`[${requestId}] üì§ Uploading PDF to: ${pdfStoragePath}`);
    const { error: pdfUploadError } = await supabase.storage
      .from('project-plans')
      .upload(pdfStoragePath, pdfBuffer, {
        contentType: 'application/pdf',
        cacheControl: '31536000',
        upsert: true
      });
    
    if (pdfUploadError) {
      console.error(`[${requestId}] ‚ùå PDF upload failed:`, pdfUploadError);
      throw pdfUploadError;
    }
    
    console.log(`[${requestId}] ‚úÖ PDF uploaded successfully`);
    
    // Mettre √† jour file_url
    await updatePlanStatus(planId, 'processing', 2, {
      file_url: pdfStoragePath
    });
    
    // Mettre √† jour le statut
    await updatePlanStatus(planId, 'processing', 5);
    onProgress?.(5);
    
    // 1Ô∏è‚É£ Linearize
    console.log(`[${requestId}] ‚ö° Linearizing...`);
    execSync(`qpdf "${inputPdf}" --linearize "${linearizedPdf}"`, {
      timeout: 120000, // 2 minutes max
    });
    
    const pageCount = Number(
      execSync(`qpdf --show-npages "${linearizedPdf}"`).toString().trim()
    );
    
    console.log(`[${requestId}] üìä Pages: ${pageCount}`);
    
    await updatePlanStatus(planId, 'processing', 10);
    onProgress?.(10);
    
    // 2Ô∏è‚É£ Traiter les pages EN PARALL√àLE
    // Ajuster selon votre RAM : 8GB=2, 16GB=4, 32GB=8
    const limit = pLimit(4); // 4 pages en parall√®le max
    
    const pagePromises = [];
    let processingComplete = false; // Flag pour arr√™ter les updates
    
    for (let i = 1; i <= pageCount; i++) {
      pagePromises.push(
        limit(() => processPage({
          linearizedPdf,
          pageNumber: i,
          pageCount,
          pagesDir,
          projectId,
          planId,
          fileName,
          requestId,
          supabaseClient: supabase,
          onPageProgress: (pageProgress) => {
            // Ne mettre √† jour que si le traitement n'est pas termin√©
            if (!processingComplete && pageProgress < 100) {
              // Calculer la progression globale
              const baseProgress = 10;
              const processingRange = 80; // 10% ‚Üí 90%
              const globalProgress = baseProgress + (processingRange * pageProgress / 100);
              
              updatePlanStatus(planId, 'processing', Math.round(globalProgress));
              onProgress?.(Math.round(globalProgress));
            }
          }
        }))
      );
    }
    
    const results = await Promise.all(pagePromises);
    
    // Marquer le traitement comme termin√© pour arr√™ter les updates asynchrones
    processingComplete = true;
    
    console.log(`[${requestId}] ‚úÖ All pages processed`);
    
    // 3Ô∏è‚É£ Finaliser - Mettre √† jour le plan principal
   // const safeBase = fileName.replace(/\.pdf$/i, '').replace(/[^a-z0-9]/gi, '_');
    const name = `${safeBase}-page1`; // Utiliser la premi√®re page comme r√©f√©rence
    const remoteTilesPath = `${projectId}/tiles/${name}`;
    
    console.log(`[${requestId}] üìä Final update data:`);
    console.log(`[${requestId}]   - status: ready`);
    console.log(`[${requestId}]   - progress: 100`);
    console.log(`[${requestId}]   - width: ${results[0].width}`);
    console.log(`[${requestId}]   - height: ${results[0].height}`);
    console.log(`[${requestId}]   - pages: ${pageCount}`);
    console.log(`[${requestId}]   - tiles_path: ${remoteTilesPath}`);
    
    await updatePlanStatus(planId, 'ready', 100, {
      width: results[0].width,
      height: results[0].height,
      pages: pageCount,
      tiles_path: remoteTilesPath
    });
    
    console.log(`[${requestId}] ‚úÖ Status updated to "ready"`);
    
    onProgress?.(100);
    
    // Cleanup
    await fs.remove(tmpDir);
    
    return {
      success: true,
      planId,
      pages: pageCount
    };
    
  } catch (error) {
    console.error(`[${requestId}] ‚ùå Processing error:`, error);
    
    await updatePlanStatus(planId, 'failed', 0, {
      error_message: error.message
    });
    
    if (tmpDir) await fs.remove(tmpDir).catch(() => {});
    
    throw error;
  }
}

/**
 * Traiter une page individuelle
 */
async function processPage({
  linearizedPdf,
  pageNumber,
  pageCount,
  pagesDir,
  projectId,
  planId,
  fileName,
  requestId,
  supabaseClient,
  onPageProgress
}) {
  const safeBase = fileName.replace(/\.pdf$/i, '').replace(/[^a-z0-9]/gi, '_');
  const name = `${safeBase}-page${pageNumber}`;
  const pagePdf = path.join(pagesDir, `${name}.pdf`);
  const outputPng = path.join(pagesDir, `${name}.png`);
  const previewPng = path.join(pagesDir, `${name}_preview.png`);
  const tilesBaseDir = path.join(pagesDir, `${name}_tiles`);
  
  try {
    // 1. Extract page
    execSync(
      `qpdf "${linearizedPdf}" --pages "${linearizedPdf}" ${pageNumber} -- "${pagePdf}"`,
      { timeout: 60000 }
    );
    onPageProgress?.(20);
    
    // 2. Rasterize avec Ghostscript (haute r√©solution pour les tiles - 600 DPI)
    const gsCommand = process.platform === 'win32' ? 'gswin64c' : 'gs';
    execSync(
      `${gsCommand} -dSAFER -dBATCH -dNOPAUSE -sDEVICE=png16m -r600 -dBufferSpace=1000000000 -sOutputFile="${outputPng}" "${pagePdf}"`,
      { 
        maxBuffer: 1024 * 1024 * 100, // 100MB buffer
        timeout: 120000 // 2 minutes max par page
      }
    );
    onPageProgress?.(40);
    
    // 2.5. Cr√©er une version basse r√©solution pour l'affichage direct (150 DPI)
    console.log(`[${requestId}] üñºÔ∏è  Generating preview PNG at 150 DPI...`);
    execSync(
      `${gsCommand} -dSAFER -dBATCH -dNOPAUSE -sDEVICE=png16m -r150 -dBufferSpace=500000000 -sOutputFile="${previewPng}" "${pagePdf}"`,
      { 
        maxBuffer: 1024 * 1024 * 50, // 50MB buffer
        timeout: 120000
      }
    );
    onPageProgress?.(50);
    
    // 2.6. Upload du PNG basse r√©solution vers Supabase (pour affichage)
    const previewStoragePath = `${projectId}/previews/${name}.png`;
    console.log(`[${requestId}] üì§ Uploading preview PNG (150 DPI) to: ${previewStoragePath}`);
    
    const previewBuffer = await fs.readFile(previewPng);
    console.log(`[${requestId}] üì¶ Preview PNG size: ${(previewBuffer.length / 1024 / 1024).toFixed(2)} MB`);
    
    const { error: previewUploadError } = await supabaseClient.storage
      .from('project-plans')
      .upload(previewStoragePath, previewBuffer, {
        contentType: 'image/png',
        cacheControl: '31536000',
        upsert: true
      });
    
    if (previewUploadError) {
      console.error(`[${requestId}] ‚ùå Preview PNG upload failed:`, previewUploadError);
      throw previewUploadError;
    }
    
    console.log(`[${requestId}] ‚úÖ Preview PNG uploaded successfully`);
    
    // Mettre √† jour png_url pour la premi√®re page uniquement
    if (pageNumber === 1) {
      const { error: updateError } = await supabaseClient
        .from('plans')
        .update({ 
          png_url: previewStoragePath,
          processing_progress: 55
        })
        .eq('id', planId);
      
      if (updateError) {
        console.error(`[${requestId}] ‚ùå PNG URL update failed:`, updateError);
      }
    }
    
    // 3. Tiling avec Sharp (utilise le PNG haute r√©solution)
    const sharp = (await import('sharp')).default;
    
    const image = sharp(outputPng, { 
      limitInputPixels: false,
      sequentialRead: true // Optimisation m√©moire
    });
    
    const metadata = await image.metadata();
    
    await image
      .tile({
        size: 512,
        layout: 'dz',
        container: 'fs',
        // ‚úÖ JPEG par d√©faut (plus performant pour les plans PDF)
        // Sharp g√©n√®re des .jpeg automatiquement
      })
      .toFile(tilesBaseDir);
    
    onPageProgress?.(70);
    
    // 4. Upload vers Supabase (optimis√© avec batch)
    const filesDir = `${tilesBaseDir}_files`;
    const remoteTilesPath = `${projectId}/tiles/${name}`;
    
    await uploadTilesBatch(filesDir, `${remoteTilesPath}_files`, requestId);
    
    onPageProgress?.(90);
    
    // 5. Pas de cr√©ation d'entr√©e s√©par√©e par page
    // Les tiles sont simplement upload√©es et le plan principal sera mis √† jour √† la fin
    
    // Cleanup PNG et preview pour lib√©rer l'espace disque
    await fs.remove(outputPng);
    await fs.remove(previewPng);
    await fs.remove(pagePdf);
    await fs.remove(tilesBaseDir);
    await fs.remove(filesDir);
    
    onPageProgress?.(100);
    
    console.log(`[${requestId}] ‚úÖ Page ${pageNumber}/${pageCount} completed`);
    
    return { width: metadata.width, height: metadata.height };
    
  } catch (error) {
    console.error(`[${requestId}] ‚ùå Page ${pageNumber} failed:`, error);
    
    if (error.killed) {
      throw new Error(`Page ${pageNumber} timeout - PDF trop complexe`);
    }
    
    throw error;
  }
}

/**
 * Upload des tiles par batch (optimis√©)
 */
async function uploadTilesBatch(localPath, remotePrefix, requestId) {
  console.log(`[${requestId}] üì§ Starting upload from: ${localPath}`);
  console.log(`[${requestId}] üì§ Remote prefix: ${remotePrefix}`);
  
  // V√©rifier que le dossier existe
  const exists = await fs.pathExists(localPath);
  if (!exists) {
    throw new Error(`Tiles directory not found: ${localPath}`);
  }
  
  const limit = pLimit(10); // 10 uploads simultan√©s max
  const uploadPromises = [];
  
  const collectFiles = async (dir, prefix = '') => {
    const items = await fs.readdir(dir);
    console.log(`[${requestId}] üìÇ Found ${items.length} items in ${dir}`);
    
    for (const item of items) {
      const fullPath = path.join(dir, item);
      const remotePath = `${remotePrefix}${prefix}/${item}`;
      const stat = await fs.stat(fullPath);
      
      if (stat.isDirectory()) {
        console.log(`[${requestId}] üìÅ Entering directory: ${item}`);
        await collectFiles(fullPath, `${prefix}/${item}`);
      } else {
        console.log(`[${requestId}] üìÑ Queueing file: ${remotePath}`);
        uploadPromises.push(
          limit(async () => {
            const buffer = await fs.readFile(fullPath);
            console.log(`[${requestId}] ‚¨ÜÔ∏è  Uploading: ${remotePath} (${buffer.length} bytes)`);
            
            const { error } = await supabase.storage
              .from('project-plans')
              .upload(remotePath, buffer, {
                contentType: item.endsWith('.jpeg') || item.endsWith('.jpg') ? 'image/jpeg' : 'image/png',
                cacheControl: '31536000', // 1 an
                upsert: true
              });
            
            if (error) {
              console.error(`[${requestId}] ‚ùå Upload failed: ${remotePath}`, error.message);
              throw error;
            }
            
            console.log(`[${requestId}] ‚úÖ Uploaded: ${remotePath}`);
          })
        );
      }
    }
  };
  
  await collectFiles(localPath);
  
  console.log(`[${requestId}] ‚è≥ Waiting for ${uploadPromises.length} uploads to complete...`);
  await Promise.all(uploadPromises);
  
  console.log(`[${requestId}] ‚úÖ Uploaded ${uploadPromises.length} tiles`);
}

/**
 * Mettre √† jour le statut du plan
 */
async function updatePlanStatus(planId, status, progress, extraData = {}) {
  const { data, error } = await supabase
    .from('plans')
    .update({
      status,
      processing_progress: progress,
      ...extraData,
      updated_at: new Date().toISOString()
    })
    .eq('id', planId);
  
  if (error) {
    console.error(` Failed to update plan status:`, error);
    throw error;
  }
  
  return data;
}

export { processPdfToTiles };